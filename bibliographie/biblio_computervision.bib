@misc{aikonAikonplatformAikon2025,
  title = {Aikon-Platform/Aikon},
  author = {Aikon},
  year = {2025},
  month = jul,
  urldate = {2025-08-02},
  abstract = {Computer vision platform for the Digital Humanities},
  keywords = {computer-vision,digital-humanities,visual-studies}
}

@misc{albouyAIKONComputerVision,
  title = {{{AIKON}} : {{Computer Vision Platform}} for {{Digital Humanities}}},
  author = {Albouy, Ségolène and Norindr, Jade and Aouinti, Fouad and Grometto, Clara and Champenois, Robin and Lazaris, Stavros and Guilbaud, Alexandre and Husson, Matthieu and Aubry, Mathieu}
}

@phdthesis{albouyMediationDonneesRecherche2019,
  type = {{other}},
  title = {{Médiation des données de la recherche : Elaboration d'une plateforme en ligne pour une base de tables astronomiques anciennes}},
  author = {Albouy, Ségolène},
  year = {2019},
  address = {Paris},
  urldate = {2025-08-03},
  langid = {french},
  school = {Ecole nationale des chartes}
}

@misc{ArtMiner,
  title = {{{ArtMiner}}},
  urldate = {2025-08-01},
  howpublished = {https://imagine.enpc.fr/\textasciitilde shenx/ArtMiner/},
  file = {/home/lucie-ledieu/snap/zotero-snap/common/Zotero/storage/LUSJZLM3/ArtMiner.html}
}

@misc{Corpus,
  title = {Corpus},
  journal = {VHS project},
  urldate = {2025-08-01},
  abstract = {The work we will be carried out on on four original corpora selected first for their relevance to the problem of the circulation of scientific knowledge through illustration, and second for their chronological, geographical...},
  howpublished = {https://vhs.hypotheses.org/corpus},
  langid = {american},
  file = {/home/lucie-ledieu/snap/zotero-snap/common/Zotero/storage/T3FDJ4VX/corpus.html}
}

@misc{EnHeritEnhancingHeritage,
  title = {{{EnHerit}} : {{Enhancing Heritage Image Databases}} – {{ANR JCJC}} Project 17-{{CE23-0008}}},
  shorttitle = {{{EnHerit}}},
  urldate = {2025-08-01},
  howpublished = {https://enherit.enpc.fr/},
  langid = {american},
  file = {/home/lucie-ledieu/snap/zotero-snap/common/Zotero/storage/J2K9KGBQ/enherit.enpc.fr.html}
}

@article{fouadComputerVisionHistorical2023,
  title = {Computer {{Vision}} and {{Historical Scientific Illustrations}}},
  author = {Fouad, {\relax AOUINTI} and Sonat, BALTACI Zeynep and Mathieu, {\relax AUBRY} and Alexandre, {\relax GUILBAUD} and Stavros, {\relax LAZARIS}},
  year = {2023},
  abstract = {The VHS project (computer Vision and Historical analysis of Scientific illustration circulation) proposes a new approach to the historical study of the circulation of scientific knowledge based on new methods of illustration analysis. Our contributions in this paper are twofold. First, we present a semi-automatic interactive pipeline for scientific illustration extraction that allows and incorporates expert feedback from historians. Second, we introduce a new dataset of scientific illustrations from the Middle Ages to the modern era consisting of 8k illustrations validated by historians and a total number of 235k illustrations obtained from 405k corpora pages. We further discuss our current research for identifying a series of related illustrations from this data.},
  langid = {english},
  file = {/home/lucie-ledieu/snap/zotero-snap/common/Zotero/storage/QKTIE7TD/Fouad et al. - 2023 - Computer Vision and Historical Scientific Illustrations.pdf}
}

@misc{HIGHVISIONProjet2025,
  title = {{HIGH VISION – Projet ANR}},
  year = {2025},
  month = jun,
  urldate = {2025-08-04},
  langid = {french},
  file = {/home/lucie-ledieu/snap/zotero-snap/common/Zotero/storage/IMGVTUCL/highvision.hypotheses.org.html}
}

@article{kalleliEditingAnalysingHistorical2023,
  title = {Editing and {{Analysing Historical Astronomical Diagrams}} with {{Artificial Intelligence}}},
  author = {Kalleli, Syrine and Trigg, Scott and Albouy, Ségolène and Gessner, Samuel and Husson, Mathieu and Aubry, Mathieu},
  year = {2023},
  abstract = {The EIDA project explores the historical use of astronomical diagrams across Asia, Africa, and Europe. We aim to develop automatic image analysis tools to analyze and edit these diagrams without human annotation, gaining a refined understanding of their role in shaping and transmitting astronomy. In this paper, we present a baseline method to detects lines and circles in historical diagrams, based on text removal, edge detection and RANSAC. We compare this strong baseline to a deep learning approach based on LETR. This work contributes to historical diagram vectorization, enabling novel methods of comparison and clustering, and offering fresh insights into the vast corpus of astronomical diagrams.},
  file = {/home/lucie-ledieu/snap/zotero-snap/common/Zotero/storage/5TQSMRHM/Kalleli et al. - 2023 - Editing and Analysing Historical Astronomical Diagrams with Artificial Intelligence.pdf}
}

@misc{kalleliHistoricalAstronomicalDiagrams2024,
  title = {Historical {{Astronomical Diagrams Decomposition}} in {{Geometric Primitives}}},
  author = {Kalleli, Syrine and Trigg, Scott and Albouy, Ségolène and Husson, Mathieu and Aubry, Mathieu},
  year = {2024},
  month = mar,
  number = {arXiv:2403.08721},
  eprint = {2403.08721},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.08721},
  urldate = {2025-07-31},
  abstract = {Automatically extracting the geometric content from the hundreds of thousands of diagrams drawn in historical manuscripts would enable historians to study the diffusion of astronomical knowledge on a global scale. However, state-of-the-art vectorization methods, often designed to tackle modern data, are not adapted to the complexity and diversity of historical astronomical diagrams. Our contribution is thus twofold. First, we introduce a unique dataset of 303 astronomical diagrams from diverse traditions, ranging from the XIIth to the XVIIIth century, annotated with more than 3000 line segments, circles and arcs. Second, we develop a model that builds on DINO-DETR to enable the prediction of multiple geometric primitives. We show that it can be trained solely on synthetic data and accurately predict primitives on our challenging dataset. Our approach widely improves over the LETR baseline, which is restricted to lines, by introducing a meaningful parametrization for multiple primitives, jointly training for detection and parameter refinement, using deformable attention and training on rich synthetic data. Our dataset and code are available at our project webpage: http://imagine.enpc.fr/\textasciitilde kallelis/icdar2024/.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/lucie-ledieu/snap/zotero-snap/common/Zotero/storage/8YSRY3SX/Kalleli et al. - 2024 - Historical Astronomical Diagrams Decomposition in Geometric Primitives.pdf}
}

@misc{kaouaImageCollationMatching2021,
  title = {Image {{Collation}}: {{Matching}} Illustrations in Manuscripts},
  shorttitle = {Image {{Collation}}},
  author = {Kaoua, Ryad and Shen, Xi and Durr, Alexandra and Lazaris, Stavros and Picard, David and Aubry, Mathieu},
  year = {2021},
  month = aug,
  number = {arXiv:2108.08109},
  eprint = {2108.08109},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2108.08109},
  urldate = {2025-07-31},
  abstract = {Illustrations are an essential transmission instrument. For an historian, the first step in studying their evolution in a corpus of similar manuscripts is to identify which ones correspond to each other. This image collation task is daunting for manuscripts separated by many lost copies, spreading over centuries, which might have been completely re-organized and greatly modified to adapt to novel knowledge or belief and include hundreds of illustrations. Our contributions in this paper are threefold. First, we introduce the task of illustration collation and a large annotated public dataset to evaluate solutions, including 6 manuscripts of 2 different texts with more than 2 000 illustrations and 1 200 annotated correspondences. Second, we analyze state of the art similarity measures for this task and show that they succeed in simple cases but struggle for large manuscripts when the illustrations have undergone very significant changes and are discriminated only by fine details. Finally, we show clear evidence that significant performance boosts can be expected by exploiting cycle-consistent correspondences. Our code and data are available on http://imagine.enpc.fr/\textasciitilde shenx/ImageCollation.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/lucie-ledieu/snap/zotero-snap/common/Zotero/storage/78KLX8VW/Kaoua et al. - 2021 - Image Collation Matching illustrations in manuscripts.pdf}
}

@misc{MiradorHome,
  title = {Mirador — {{Home}}},
  urldate = {2025-08-03},
  howpublished = {https://projectmirador.org/},
  file = {/home/lucie-ledieu/snap/zotero-snap/common/Zotero/storage/VW77TLX2/projectmirador.org.html}
}

@phdthesis{norindrTraitementSourcesHistoriques2023,
  type = {{other}},
  title = {{Le traitement des sources historiques par la vision artificielle : l'exemple des manuscrits d'astronomie de tradition ptoléméenne}},
  shorttitle = {{Le traitement des sources historiques par la vision artificielle}},
  author = {Norindr, Jade},
  year = {2023},
  pages = {152},
  address = {Paris},
  urldate = {2025-08-01},
  abstract = {Ce mémoire a été réalisé dans le cadre du Master Technologies numériques appliquées à l’histoire de l’École nationale des chartes. Il est rédigé suite à un stage de quatre mois à l’Observatoire de Paris au sein du projet EIDA, portant sur les diagrammes astronomiques de tradition ptoléméenne du VIIIe au XVIIIe siècle et intégrant des techniques de vision artificielle pour le traitement de ses sources. Ce mémoire expose le développement d’outils pour cette intégration, et la conception d’une chaîne de traitement accompagnée de normes et de méthodes pour l’application d’algorithmes de vision dans le cadre d’un projet de recherche en humanités.},
  langid = {french},
  school = {Ecole nationale des chartes},
  file = {/home/lucie-ledieu/snap/zotero-snap/common/Zotero/storage/9CHR599H/Norindr - 2023 - Le traitement des sources historiques par la vision artificielle  l'exemple des manuscrits d'astron.pdf}
}

@misc{Presentation,
  title = {Presentation},
  journal = {VHS project},
  urldate = {2025-08-01},
  abstract = {The VHS project proposes a new approach to the historical study of the circulation of scientific knowledge based on new methods of illustration analysis. Thanks to the recent developments in AI, and Computer Vision,...},
  howpublished = {https://vhs.hypotheses.org/presentation},
  langid = {american},
  file = {/home/lucie-ledieu/snap/zotero-snap/common/Zotero/storage/GM4T9FYQ/presentation.html}
}

@misc{QuestceQueLapprentissage2023,
  title = {{Qu’est-ce que l’apprentissage auto-supervisé ? | IBM}},
  shorttitle = {{Qu’est-ce que l’apprentissage auto-supervisé ?}},
  year = {2023},
  month = dec,
  urldate = {2025-08-01},
  abstract = {L'apprentissage auto-supervisé est une technique de machine learning qui utilise l'apprentissage non supervisé pour des tâches qui, habituellement, nécessitent un apprentissage supervisé, le tout sans données étiquetées.},
  howpublished = {https://www.ibm.com/fr-fr/think/topics/self-supervised-learning},
  langid = {french},
  file = {/home/lucie-ledieu/snap/zotero-snap/common/Zotero/storage/4NHPPEGG/self-supervised-learning.html}
}

@misc{shenDiscoveringVisualPatterns2019,
  title = {Discovering {{Visual Patterns}} in {{Art Collections}} with {{Spatially-consistent Feature Learning}}},
  author = {Shen, Xi and Efros, Alexei A. and Aubry, Mathieu},
  year = {2019},
  month = mar,
  number = {arXiv:1903.02678},
  eprint = {1903.02678},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1903.02678},
  urldate = {2025-07-02},
  abstract = {Our goal in this paper is to discover near duplicate patterns in large collections of artworks. This is harder than standard instance mining due to differences in the artistic media (oil, pastel, drawing, etc), and imperfections inherent in the copying process. Our key technical insight is to adapt a standard deep feature to this task by fine-tuning it on the specific art collection using self-supervised learning. More specifically, spatial consistency between neighbouring feature matches is used as supervisory fine-tuning signal. The adapted feature leads to more accurate style-invariant matching, and can be used with a standard discovery approach, based on geometric verification, to identify duplicate patterns in the dataset. The approach is evaluated on several different datasets and shows surprisingly good qualitative discovery results. For quantitative evaluation of the method, we annotated 273 near duplicate details in a dataset of 1587 artworks attributed to Jan Brueghel and his workshop1. Beyond artworks, we also demonstrate improvement on localization on the Oxford5K photo dataset as well as on historical photograph localization on the Large Time Lags Location (LTLL) dataset.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/lucie-ledieu/snap/zotero-snap/common/Zotero/storage/TZ7ALDPK/Shen et al. - 2019 - Discovering Visual Patterns in Art Collections with Spatially-consistent Feature Learning.pdf}
}

@misc{shenLearningCosegmentationSegment2022,
  title = {Learning {{Co-segmentation}} by {{Segment Swapping}} for {{Retrieval}} and {{Discovery}}},
  author = {Shen, Xi and Efros, Alexei A. and Joulin, Armand and Aubry, Mathieu},
  year = {2022},
  month = mar,
  number = {arXiv:2110.15904},
  eprint = {2110.15904},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2110.15904},
  urldate = {2025-07-31},
  abstract = {The goal of this work is to efficiently identify visually similar patterns in images, e.g. identifying an artwork detail copied between an engraving and an oil painting, or recognizing parts of a night-time photograph visible in its daytime counterpart. Lack of training data is a key challenge for this co-segmentation task. We present a simple yet surprisingly effective approach to overcome this difficulty: we generate synthetic training pairs by selecting segments in an image and copy-pasting them into another image. We then learn to predict the repeated region masks. We find that it is crucial to predict the correspondences as an auxiliary task and to use Poisson blending and style transfer on the training pairs to generalize on real data. We analyse results with two deep architectures relevant to our joint image analysis task: a transformer-based architecture and Sparse Nc-Net, a recent network designed to predict coarse correspondences using 4D convolutions. We show our approach provides clear improvements for artwork details retrieval on the Brueghel dataset and achieves competitive performance on two place recognition benchmarks, Tokyo247 and Pitts30K. We also demonstrate the potential of our approach for unsupervised image collection analysis by introducing a spectral graph clustering approach to object discovery and demonstrating it on the object discovery dataset of [49] and the Brueghel dataset. Our code and data are available at http://imagine.enpc.fr/ \textasciitilde shenx/SegSwap/.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/lucie-ledieu/snap/zotero-snap/common/Zotero/storage/S9EUL838/Shen et al. - 2022 - Learning Co-segmentation by Segment Swapping for Retrieval and Discovery.pdf}
}
